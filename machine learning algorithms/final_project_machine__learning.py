# -*- coding: utf-8 -*-
"""final_project_machine _learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1szjtG1DT-Zw1beR7O8k3yBuAI-HB4bZD
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error,classification_report,r2_score,accuracy_score,precision_score, recall_score, f1_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import DecisionTreeRegressor
from sklearn.neighbors import KNeighborsRegressor,KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.preprocessing import LabelEncoder

df = pd.read_csv('/content/house_data.csv')

"""#Exploratory Data Analysis

"""

df.head()

df.columns

df.info()

df.bedrooms.unique()

df['bedrooms'].value_counts()

df.price.unique()

df.bedrooms.unique()

df.floors.unique()

df.view.unique()

df.condition.unique()

df.grade.unique()

df.yr_built.unique()

df.yr_renovated.unique()

def print_value_counts(df):
    columns = ["bedrooms", "bathrooms", "floors", "view", "condition", "grade", "yr_built", "yr_renovated"]
    for column in columns:
        print(f"Value counts for '{column}':")
        print(df[column].value_counts())
        print("\n")

print_value_counts(df)

def print_min_max_values(df):
    columns = ["bedrooms", "bathrooms", "floors", "view", "condition", "grade", "yr_built", "yr_renovated"]
    for column in columns:
        print(f"min value for '{column}':, {min(df[column])}")
        print(f"max value for '{column}':, {max(df[column])}")
        print("\n")
print_min_max_values(df)

"""#Data preprocessing"""

df.isna().value_counts()

df.shape

df.drop_duplicates(inplace=True)

df.shape

df1 = df[df['bedrooms'] <= 10]

df1 = df1.drop(['id','date'], axis=1)

df1.head()

sns.pairplot(df1[['price','bedrooms','bathrooms','floors','view','condition','grade','yr_built','yr_renovated','sqft_lot']])

plt.figure(figsize=(15,10))
columns =['price','bedrooms','bathrooms','sqft_living','floors','grade','yr_built','condition','sqft_lot']
sns.heatmap(df1[columns].corr(),annot=True)

df1['Rating'] = ['Good' if x < 7 else 'Excellent' for x in df1['grade']]

"""#Data Modeling"""

df2 = df1.drop(['Rating'],axis=1)

df2['bathrooms'] = df2['bathrooms'].apply(np.int64)
df2['price'] = df2['price'].apply(np.int64)

df2.info()

X = df2.iloc[:,3].values
y = df2.iloc[:,0].values
X = X.reshape(-1, 1)
y = y.reshape(-1, 1)
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0)

regressor = LinearRegression()
regressor.fit(X_train,y_train)
y_pred = regressor.predict(X_test)

finaldf = pd.DataFrame({'Actual': y_test.flatten(), 'Predicted': y_pred.flatten()})
finaldf

rmse = np.sqrt(mean_squared_error(y_test, y_pred))

mae = mean_absolute_error(y_test, y_pred)
r_squared = r2_score(y_test, y_pred)

percent_accuracy = r_squared * 100

print(f"Percent Accuracy: {percent_accuracy:.2f}%")

print("Root Mean Squared Error (RMSE):", rmse)
print("Mean Absolute Error (MAE):", mae)

# Find the 75th and 25th percentiles
seventy_fifth = df2['sqft_living'].quantile(0.75)
twenty_fifth = df2['sqft_living'].quantile(0.25)

# Calculate iqr
prices_iqr = seventy_fifth - twenty_fifth

# Calculate the thresholds
upper = seventy_fifth + (1.5 * prices_iqr)
lower = twenty_fifth - (1.5 * prices_iqr)

# Subset the data
df2 = df2[(df2['sqft_living'] > lower) & (df2['sqft_living'] < upper)]

X = df2.iloc[:,3].values
y = df2.iloc[:,0].values
X = X.reshape(-1, 1)
y = y.reshape(-1, 1)
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0)
regressor = LinearRegression()
regressor.fit(X_train,y_train)
y_pred = regressor.predict(X_test)

rmse = np.sqrt(mean_squared_error(y_test, y_pred))

mae = mean_absolute_error(y_test, y_pred)
r_squared = r2_score(y_test, y_pred)

percent_accuracy = r_squared * 100

print(f"Percent Accuracy: {percent_accuracy:.2f}%")

print("Root Mean Squared Error (RMSE):", rmse)
print("Mean Absolute Error (MAE):", mae)

"""the outliers was helpful for the accuracy"""

# X(Independent variables) and y(target variables)
X = df2.iloc[:,1:].values
y = df2.iloc[:,0].values

#Splitting the data into train,test data
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=0)

regressor = LinearRegression()
regressor.fit(X_train,y_train)

y_pred = regressor.predict(X_test)

rmse = np.sqrt(mean_squared_error(y_test, y_pred))

mae = mean_absolute_error(y_test, y_pred)
r_squared = r2_score(y_test, y_pred)

percent_accuracy = r_squared * 100

print(f"Percent Accuracy: {percent_accuracy:.2f}%")

print("Root Mean Squared Error (RMSE):", rmse)
print("Mean Absolute Error (MAE):", mae)

y_test.flatten()
y_pred.flatten()
#Now compare the actual output values for X_test with the predicted values, execute the following script:
finaldf = pd.DataFrame({'Actual': y_test.flatten(), 'Predicted': y_pred.flatten()})
finaldf

# @title Actual vs Predicted

from matplotlib import pyplot as plt
finaldf.plot(kind='scatter', x='Actual', y='Predicted', s=32, alpha=.8)
plt.gca().spines[['top', 'right',]].set_visible(False)

X = df2.iloc[:, 1:].values
y = df2.iloc[:, 0].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

dt_regressor = DecisionTreeRegressor(random_state=0)

dt_regressor.fit(X_train, y_train)

y_pred_dt = dt_regressor.predict(X_test)

r_squared_dt = r2_score(y_test, y_pred_dt)
percent_accuracy_dt = r_squared_dt * 100

rmse = np.sqrt(mean_squared_error(y_test, y_pred))

mae = mean_absolute_error(y_test, y_pred)

print(f"Decision Tree Regressor Percent Accuracy: {percent_accuracy_dt:.2f}%")
print("Root Mean Squared Error (RMSE):", rmse)
print("Mean Absolute Error (MAE):", mae)

knn_regressor = KNeighborsRegressor(n_neighbors=5)
knn_regressor.fit(X_train, y_train)
y_pred_dt = knn_regressor.predict(X_test)

r_squared_dt = r2_score(y_test, y_pred_dt)
percent_accuracy_dt = r_squared_dt * 100

rmse = np.sqrt(mean_squared_error(y_test, y_pred))

mae = mean_absolute_error(y_test, y_pred)

print(f"Decision Tree Regressor Percent Accuracy: {percent_accuracy_dt:.2f}%")


print("Root Mean Squared Error (RMSE):", rmse)
print("Mean Absolute Error (MAE):", mae)

"""#Classification"""

df1['Rating']

df1.Rating.unique()

label_encoder = LabelEncoder()
df1['Rating'] = label_encoder.fit_transform(df1['Rating'])

X = df1.drop('Rating', axis=1).values
y = df1['Rating'].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

"""Naive Bayes Classifier

"""

nb_classifier = GaussianNB()

nb_classifier.fit(X_train, y_train)

y_pred_nb = nb_classifier.predict(X_test)

accuracy_nb = accuracy_score(y_test, y_pred_nb)
precision_nb = precision_score(y_test, y_pred_nb, average='weighted')
recall_nb = recall_score(y_test, y_pred_nb, average='weighted')
f1_nb = f1_score(y_test, y_pred_nb, average='weighted')

print(f"Naive Bayes Classifier Accuracy: {accuracy_nb:.2f}")
print(f"Naive Bayes Classifier - Precision: {precision_nb:.2f}, Recall: {recall_nb:.2f}, F1-Score: {f1_nb:.2f}")

"""Decision Tree Classifier

"""

dt_classifier = DecisionTreeClassifier(random_state=0)

dt_classifier.fit(X_train, y_train)

y_pred_dt = dt_classifier.predict(X_test)

accuracy_dt = accuracy_score(y_test, y_pred_dt)
precision_dt = precision_score(y_test, y_pred_dt, average='weighted')
recall_dt = recall_score(y_test, y_pred_dt, average='weighted')
f1_dt = f1_score(y_test, y_pred_dt, average='weighted')

print(f"Decision Tree Classifier Accuracy: {accuracy_dt:.2f}")
print(f"Decision Tree Classifier - Precision: {precision_dt:.2f}, Recall: {recall_dt:.2f}, F1-Score: {f1_dt:.2f}")

"""K nearst"""

knn_classifier = KNeighborsClassifier(n_neighbors=5)

knn_classifier.fit(X_train, y_train)

y_pred_knn = knn_classifier.predict(X_test)

accuracy_knn = accuracy_score(y_test, y_pred_knn)
precision_knn = precision_score(y_test, y_pred_knn, average='weighted')
recall_knn = recall_score(y_test, y_pred_knn, average='weighted')
f1_knn = f1_score(y_test, y_pred_knn, average='weighted')

print(f"K-Nearest Neighbors Classifier Accuracy: {accuracy_knn:.2f}")
print(f"K-Nearest Neighbors Classifier - Precision: {precision_knn:.2f}, Recall: {recall_knn:.2f}, F1-Score: {f1_knn:.2f}")

df1 = df1.drop('Rating', axis=1)
df1['Rating'] = ['Good' if x < 7 else 'Excellent' for x in df1['grade']]
df1.to_csv('/content/cleaned_data.csv', index=False)